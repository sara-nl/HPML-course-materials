{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import all packages we need and set the correct device. If a CUDA compatible GPU is found, it will be used. If not, everything will be done on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the data\n",
    "\n",
    "We make two classes for processing our data. The first class, TextEncoder, will be used to encode and decode text data, since we cannot use strings as input directly. All unique words will be found and mapped to an integer. Apart from the unique words we extract from the data, TextEncoder will also have an unknown token: [UNK]. This token will be used if, during inference, we encounter a word that is not part of our vocabulary.\n",
    "\n",
    "Our second class, TextData, will handle the reading and sampling of our input data. It will use and instance of the TextEncoder class to encode our data. TextData also lets us sample sequences of text. In order to do this, TextData needs an implementation of the \\_\\_getitem\\_\\_ method, which will tell it how to handle indices. We also need a \\_\\_len\\_\\_ method so that our TextData class can work with pytorch's DataLoader, but more on that later.\n",
    "\n",
    "All you really need to understand for now though, is that these two classes read data from a txt file and encode it so we can use it for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder():\n",
    "    def __init__(self, file_path):\n",
    "        self.vocab = set()\n",
    "        self.vocab_size = 0\n",
    "        self.encoder = dict()\n",
    "        self.decoder = dict()\n",
    "\n",
    "        self._extract_vocab(file_path)\n",
    "        self._make_encoder_decoder()\n",
    "    \n",
    "    def _extract_vocab(self, file_path):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text = file.read()\n",
    "            vocab = text.split()\n",
    "            # Tokenizing the text into words and cleaning each word\n",
    "            vocab = [re.sub('[^A-Za-z0-9]+', '', word.lower()) for word in vocab if word != \"\"]\n",
    "            # Creating a set to keep unique words\n",
    "            vocab = set(vocab)\n",
    "        # Storing vocabulary and its size (+1 for [UNK] token)\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab) + 1 # add one for unknown word token\n",
    "\n",
    "    def _make_encoder_decoder(self):\n",
    "        word_ids = range(1, self.vocab_size) # reserve 0 for unknown words\n",
    "        self.encoder = dict(zip(self.vocab, word_ids))\n",
    "        self.decoder = dict(zip(word_ids, self.vocab))\n",
    "\n",
    "        # add unknown token and id\n",
    "        self.encoder[\"[UNK]\"] = 0\n",
    "        self.decoder[0] = \"[UNK]\"\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self, file_path, text_encoder, seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.text_encoder = text_encoder\n",
    "        self.text = self._read_text(file_path)\n",
    "        self.encoded_text = self.encode_text(self.text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_text) - self.seq_len - 2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"sequence\": self.encoded_text[index : index + self.seq_len],\n",
    "            \"next_tokens\": self.encoded_text[index + 1 : index + self.seq_len + 1],\n",
    "        }\n",
    "\n",
    "    def _read_text(self, file_path):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return file.read()\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        all_words = text.split()\n",
    "        all_words = [word.lower() for word in all_words if word != \"\"]\n",
    "        encoded_words = [self.text_encoder.encoder[re.sub('[^A-Za-z0-9]+', '', word.lower())] if word in self.text_encoder.vocab else self.text_encoder.encoder[\"[UNK]\"] for word in all_words]\n",
    "\n",
    "        return np.asarray(encoded_words)\n",
    "\n",
    "    def decode_text(self, tokens):\n",
    "        sentence = []\n",
    "        for token in tokens:\n",
    "            #if token==0:\n",
    "            #    continue\n",
    "            sentence.append(self.text_encoder.decoder[token])\n",
    "\n",
    "        return \" \".join(sentence)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Once we can process our data, we need a model. In this notebook we will train a GPT (Generative Pretrained Transformer) model with pytorch, which we define as a class here. We choose which layers we want our model to have and define the forward pass, as well as a function that generates text.\n",
    "\n",
    "The model consists of three parts: \n",
    "\n",
    "<ol>\n",
    "    <li> Embedding layer. This part learns vector representations for each word in the vocabulary. Additionally, it incorporates positional embeddings to retain sequential information since transformers do not inherently comprehend order.\n",
    "    <li> Transformer Blocks: Constituting the core of the GPT model, these blocks contain the self-attention mechanism and multi-layer perceptrons (MLP). The self-attention mechanism enables the model to focus on different words for a given input, maintaining a contextual relationship between words in a sequence. Moreover, each block processes the input data in parallel (unlike RNNs or LSTMs), efficiently handling dependencies between words or sub-words.\n",
    "    <li> Linear classifier. This is an extra layer after the Transformers blocks that makes the prediction. It outputs the logits for each word in the vocabulary, which can then be transformed into probabilities using a softmax function. The word with the highest probability can be selected as the next word in the sequence during text generation\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full definition of a GPT Language Model, all of it in this single file.\n",
    "References:\n",
    "1) the official GPT-2 TensorFlow implementation released by OpenAI:\n",
    "https://github.com/openai/gpt-2/blob/master/src/model.py\n",
    "2) huggingface/transformers PyTorch implementation:\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "3) Taken and modified from the minimal GPT implementation: https://github.com/karpathy/nanoGPT/blob/master/model.py  \n",
    "\"\"\"\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        \n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                    .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "       \n",
    "        # manual implementation of attention\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y, att\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_attn, attn = self.attn(self.ln_1(x))\n",
    "        x = x + x_attn\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x, attn\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        \n",
    "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x, attn = block(x)\n",
    "\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # return final logits and last attention matrix of shape (B, NH, T, T)\n",
    "        return logits, attn\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, sample=True, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            \n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, attn = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            if sample:\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            else:\n",
    "                idx_next = torch.argmax(probs, dim=1).unsqueeze(0)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for model training and evaluation\n",
    "\n",
    "The most important function we're creating here is train\\_loop, as this is how we train our model. The generate function is used to generate text. It is called at the end of every epoch, so we can see the model improve. The last function here is print\\_model\\_size, which we simply add to give you a sense of how big such a model is. If you do play around with the hyperparameters above, you can see how this influences not only the performance, but also the size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, dataloader, criterion, optimizer, EPOCHS, PROMPT):\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = []\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            model.train()\n",
    "\n",
    "            input_sequence = batch[\"sequence\"].to(device)\n",
    "            next_tokens = batch[\"next_tokens\"].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(input_sequence)\n",
    "\n",
    "            loss = criterion(outputs.permute(0,2,1), next_tokens)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "                \n",
    "        if (epoch + 1) % 10 == 0:    \n",
    "            print(f\"[{epoch + 1}] train loss: {np.mean(losses):.3f}\")\n",
    "            sentence, _ = generate_sentence(model, dataloader, PROMPT, 32, sample=False)\n",
    "            print(\"generated sentence: \", sentence)\n",
    "                \n",
    "    print(\"Finished training.\")\n",
    "\n",
    "def generate_sentence(model, dataloader, sentence, gen_len, temperature=0.7, sample=False):\n",
    "    \"\"\"\n",
    "    Generate a text sequence using the trained model based on a provided starting sentence.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained GPT model for text generation.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader providing access to encoding/decoding utilities.\n",
    "        sentence (str): The initial seed text for generation.\n",
    "        gen_len (int): The number of additional tokens to generate.\n",
    "        temperature (float, optional): Controls the randomness of output; defaults to 0.7.\n",
    "        sample (bool, optional): If True, samples from the output distribution; defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        sentence (str): The generated text sequence.\n",
    "        attn (torch.Tensor): Attention weights from the model's last layer.\n",
    "    \"\"\"\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # tokenize your prompt text, and send it to device\n",
    "    x = torch.tensor(np.array([dataloader.dataset.encode_text(sentence)])).to(device)\n",
    "\n",
    "    # Generate new token ids using the model\n",
    "    generated_tokens, attn = model.generate(x, gen_len, sample=sample, temperature=temperature)\n",
    "    \n",
    "    # Convert the tensor of token IDs to a list and decode them into normal text\n",
    "    generated_tokens = generated_tokens.view(-1).cpu().numpy().tolist()\n",
    "    sentence = dataloader.dataset.decode_text(generated_tokens)\n",
    "\n",
    "    return sentence, attn\n",
    "    \n",
    "def print_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement()*param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement()*buffer.element_size()\n",
    "\n",
    "    size = (param_size + buffer_size) / 1024**2\n",
    "    print(\"model number of params: \", sum([np.prod(p.size()) for p in model.parameters()]))\n",
    "    print(\"model size: {:.3f}MB\".format(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your GPT!\n",
    "\n",
    "Here we call the individual parts we defined above and actually do the training.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Here we set some hyperparameters that will define how the model is trained. You can leave them as is or play with them and see what happens. The configurable training parameters are:\n",
    "<ul>\n",
    "    <li> Batch size. \n",
    "    <li> Epochs. More epochs allow the model more opportunities to learn from the data, but beware of overfitting!\n",
    "    <li> Learning rate.\n",
    "    <li> Sequence length. This determines the length of the sequences that the model will learn from. It's pivotal to balance: shorter sequences might lack context, while longer ones could challenge memory limits and computational efficiency.\n",
    "</ul>\n",
    "\n",
    "### Customizable Data and Prompt\n",
    "\n",
    "You can also customize the data feed to the model and the prompt for testing the accuracy of the model.\n",
    "You can change the DATA\\_FILE\\_PATH to any of the txt files in the Data folder, that way you can choose which data you want to train on. You can also type the PROMPT that is used to generate a sentence each epoch. Keep in mind the model will only recognize words it has seen in the txt file you train on!\n",
    "\n",
    "We have the following txt files available:\n",
    "\n",
    "<ul>\n",
    "    <li> alice_in_wonderland.txt\n",
    "    <li> dummy_text.txt\n",
    "    <li> frankenstein.txt\n",
    "    <li> romeo_and_juliet.txt\n",
    "    <li> tolkien.txt\n",
    "</ul>\n",
    "\n",
    "### Some considerations:\n",
    "<ul>\n",
    "    <li> Vocabulary Awareness: The model recognizes and generates words based on its training data. Words or styles not encountered during training might be handled less adeptly.\n",
    "    <li> Hyperparameter Impact: Feel free to experiment with the hyperparameters, observing how alterations influence training dynamics, model performance, and generated text quality.\n",
    "    <li> Data Diversity: Different text files will immerse the model in varied linguistic environments. Observe how training on 'frankenstein.txt' might differ from 'alice_in_wonderland.txt' in influencing the model's text generation style!\n",
    "    <li> Prompt Creativity: Utilize prompts to navigate the model's text generation. Observe how different prompts or seeds initiate varied continuations by the model.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "SEQUENCE_LEN = 32\n",
    "\n",
    "DATA_FILE_PATH = \"./Data/dummy_text.txt\"\n",
    "PROMPT = \"gandalf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now let's train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in the dataset: 30\n",
      "Vocabulary size: 256\n",
      "model number of params:  11200\n",
      "model size: 0.051MB\n",
      "[10] train loss: 4.592\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[20] train loss: 4.575\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[30] train loss: 4.344\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[40] train loss: 3.832\n",
      "generated sentence:  [UNK] [UNK] ipsum [UNK] ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum lorem ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum ipsum\n",
      "[50] train loss: 3.467\n",
      "generated sentence:  [UNK] it is [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] it is is is is ipsum is is ipsum ipsum is is is ipsum is [UNK] [UNK] [UNK]\n",
      "[60] train loss: 3.048\n",
      "generated sentence:  [UNK] [UNK] it from [UNK] [UNK] [UNK] [UNK] it has bonorum in the [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[70] train loss: 2.749\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] it [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[80] train loss: 2.436\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] it [UNK] [UNK] it [UNK] [UNK] [UNK] [UNK] and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] it has a line of [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[90] train loss: 2.237\n",
      "generated sentence:  [UNK] it has [UNK] it has [UNK] it has [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] it has [UNK] it has a [UNK] [UNK] [UNK] [UNK]\n",
      "[100] train loss: 1.915\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] it has [UNK] it has [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[110] train loss: 1.668\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et\n",
      "[120] train loss: 1.486\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] and [UNK] [UNK] [UNK] and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK]\n",
      "[130] train loss: 1.359\n",
      "generated sentence:  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK]\n",
      "[140] train loss: 1.220\n",
      "generated sentence:  [UNK] making it has a [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et\n",
      "[150] train loss: 1.276\n",
      "generated sentence:  [UNK] making it has a [UNK] [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] making of [UNK] [UNK] [UNK] [UNK] [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "[160] train loss: 0.968\n",
      "generated sentence:  [UNK] making it has a treatise on the theory of [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] of [UNK] [UNK] [UNK] [UNK] many desktop publishing packages\n",
      "[170] train loss: 0.858\n",
      "generated sentence:  [UNK] making it has a [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] [UNK] making this the theory of [UNK] finibus bonorum et [UNK] and [UNK] [UNK] [UNK] [UNK] [UNK] many desktop publishing\n",
      "[180] train loss: 0.760\n",
      "generated sentence:  [UNK] making it has a [UNK] finibus bonorum et [UNK] [UNK] [UNK] [UNK] finibus in [UNK] making of [UNK] finibus bonorum et [UNK] [UNK] of [UNK] [UNK] [UNK] [UNK] of [UNK] of [UNK]\n",
      "[190] train loss: 0.674\n",
      "generated sentence:  [UNK] and [UNK] making it look like readable during the cites of lorem ipsum [UNK] and [UNK] and [UNK] and [UNK] finibus bonorum et [UNK] [UNK] by [UNK] by [UNK] by cicero are\n",
      "[200] train loss: 0.638\n",
      "generated sentence:  [UNK] and [UNK] and [UNK] written in 45 [UNK] sections [UNK] from [UNK] of [UNK] content of [UNK] and [UNK] by cicero are ipsum is reproduced since the 1500s [UNK] and [UNK] and\n",
      "[210] train loss: 0.575\n",
      "generated sentence:  [UNK] [UNK] [UNK] and [UNK] written in 45 [UNK] from [UNK] from [UNK] and latin literature from [UNK] and latin also reproduced in section [UNK] contrary to popular [UNK] lorem ipsum comes from\n",
      "[220] train loss: 0.436\n",
      "generated sentence:  [UNK] making it look like readable [UNK] many desktop publishing packages and web page editors now use lorem ipsum as their default model [UNK] and a search for [UNK] [UNK] [UNK] [UNK] and\n",
      "[230] train loss: 0.379\n",
      "generated sentence:  [UNK] [UNK] look like readable [UNK] many desktop publishing packages and web page editors now use lorem ipsum as their default model [UNK] and a search for [UNK] will uncover many web sites\n",
      "[240] train loss: 0.333\n",
      "generated sentence:  [UNK] [UNK] look like readable [UNK] many desktop publishing packages and web page editors now use lorem ipsum as their default model [UNK] and a search for [UNK] will uncover many web sites\n",
      "[250] train loss: 0.332\n",
      "generated sentence:  [UNK] by injected [UNK] and [UNK] written in 45 [UNK] this book is a treatise on the theory of [UNK] very popular during the first line of lorem [UNK] ipsum dolor sit [UNK]\n",
      "[260] train loss: 0.287\n",
      "generated sentence:  [UNK] by injected [UNK] by injected [UNK] making it over 2000 years [UNK] richard [UNK] a latin professor at [UNK] college in [UNK] college in [UNK] looked up one of the more obscure\n",
      "[270] train loss: 0.263\n",
      "generated sentence:  [UNK] making it over 2000 years [UNK] richard [UNK] a latin professor at [UNK] college in [UNK] college in [UNK] college in [UNK] looked up one of the more obscure latin [UNK] from\n",
      "[280] train loss: 0.256\n",
      "generated sentence:  [UNK] [UNK] look even slightly [UNK] if you are going to use a passage of lorem [UNK] you need to be sure there [UNK] anything embarrassing hidden in the middle of [UNK] all\n",
      "[290] train loss: 0.310\n",
      "generated sentence:  [UNK] [UNK] [UNK] look even slightly [UNK] if you are going to use a passage of lorem [UNK] you need to be sure there [UNK] anything embarrassing hidden in the middle of [UNK]\n",
      "[300] train loss: 0.201\n",
      "generated sentence:  [UNK] [UNK] [UNK] look like readable [UNK] many desktop publishing packages and web page editors now use lorem ipsum as their default model [UNK] and a search for [UNK] [UNK] will uncover many\n",
      "[310] train loss: 0.186\n",
      "generated sentence:  [UNK] [UNK] look even slightly [UNK] if you are going to use a passage of lorem [UNK] you need to be sure there [UNK] anything embarrassing hidden in the middle of [UNK] all\n",
      "[320] train loss: 0.174\n",
      "generated sentence:  [UNK] [UNK] [UNK] look even slightly [UNK] if you are going to use a passage of lorem [UNK] you need to be sure there [UNK] anything embarrassing hidden in the middle of [UNK]\n",
      "[330] train loss: 0.167\n",
      "generated sentence:  [UNK] [UNK] [UNK] look even slightly [UNK] if you are going to use a passage of lorem [UNK] you need to be sure there [UNK] anything embarrassing hidden in the middle of [UNK]\n",
      "[340] train loss: 0.177\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[350] train loss: 0.162\n",
      "generated sentence:  [UNK] and going through the cites of the word in classical [UNK] discovered the undoubtable [UNK] lorem ipsum comes from sections [UNK] and [UNK] of [UNK] of [UNK] of [UNK] finibus bonorum et\n",
      "[360] train loss: 0.156\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370] train loss: 0.151\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[380] train loss: 0.154\n",
      "generated sentence:  [UNK] [UNK] finibus bonorum et [UNK] extremes of good and [UNK] by [UNK] written in 45 [UNK] this book is a treatise on the theory of [UNK] very popular during the [UNK] the\n",
      "[390] train loss: 0.148\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[400] train loss: 0.161\n",
      "generated sentence:  [UNK] it has roots in a piece of classical latin literature from 45 [UNK] making it over 2000 years [UNK] richard [UNK] lorem ipsum used in a piece of classical [UNK] the undoubtable\n",
      "[410] train loss: 0.143\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[420] train loss: 0.145\n",
      "generated sentence:  [UNK] it has been the [UNK] standard dummy text ever since the [UNK] when an unknown printer took a galley of type and scrambled it to make a type specimen [UNK] it has\n",
      "[430] train loss: 0.134\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[440] train loss: 0.127\n",
      "generated sentence:  [UNK] [UNK] written in 45 [UNK] this book is a treatise on the theory of [UNK] very popular during the [UNK] the [UNK] the [UNK] the first line of lorem [UNK] [UNK] [UNK]\n",
      "[450] train loss: 0.123\n",
      "generated sentence:  [UNK] it has survived not only five [UNK] but also the leap into electronic [UNK] remaining essentially [UNK] it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum\n",
      "[460] train loss: 0.128\n",
      "generated sentence:  [UNK] [UNK] of [UNK] finibus bonorum et [UNK] [UNK] extremes of good and [UNK] by [UNK] by [UNK] written in 45 [UNK] this book is a treatise on the theory of [UNK] very\n",
      "[470] train loss: 0.127\n",
      "generated sentence:  [UNK] [UNK] [UNK] extremes of good and [UNK] by [UNK] written in 45 [UNK] this book is a treatise on the theory of [UNK] very popular during the [UNK] the [UNK] the first\n",
      "[480] train loss: 0.131\n",
      "generated sentence:  [UNK] it has roots in a piece of classical latin literature from 45 [UNK] making it over 2000 years [UNK] richard [UNK] a latin professor at [UNK] college in [UNK] looked up one\n",
      "[490] train loss: 0.125\n",
      "generated sentence:  [UNK] [UNK] by [UNK] where can i get [UNK] there are many variations of passages of lorem ipsum [UNK] but the majority have suffered alteration in some [UNK] by injected [UNK] or randomised\n",
      "[500] train loss: 0.108\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[510] train loss: 0.108\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[520] train loss: 0.099\n",
      "generated sentence:  [UNK] it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum [UNK] and more recently with desktop publishing software like aldus pagemaker including versions of lorem [UNK] why\n",
      "[530] train loss: 0.112\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[540] train loss: 0.103\n",
      "generated sentence:  [UNK] [UNK] by cicero are also reproduced in their exact original [UNK] accompanied by english versions from the 1914 translation by [UNK] [UNK] where can i get [UNK] there are many variations of\n",
      "[550] train loss: 0.100\n",
      "generated sentence:  [UNK] it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum [UNK] and more recently with desktop publishing software like aldus pagemaker including versions of lorem [UNK] why\n",
      "[560] train loss: 0.107\n",
      "generated sentence:  [UNK] [UNK] by cicero are also reproduced in their exact original [UNK] accompanied by english versions from the 1914 translation by [UNK] [UNK] where can i get [UNK] there are many variations of\n",
      "[570] train loss: 0.104\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[580] train loss: 0.102\n",
      "generated sentence:  [UNK] it has roots in a piece of classical latin literature from 45 [UNK] therefore one of [UNK] by cicero [UNK] by cicero [UNK] by by injected [UNK] or randomised words which [UNK]\n",
      "[590] train loss: 0.093\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[600] train loss: 0.140\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[610] train loss: 0.103\n",
      "generated sentence:  [UNK] it has roots in a piece of classical latin literature from 45 [UNK] making it over 2000 years [UNK] richard [UNK] a latin professor at [UNK] college in [UNK] looked up one\n",
      "[620] train loss: 0.089\n",
      "generated sentence:  [UNK] [UNK] from a lorem ipsum [UNK] and going through the cites of the word in classical [UNK] discovered the undoubtable [UNK] lorem ipsum comes from sections [UNK] and [UNK] of [UNK] of\n",
      "[630] train loss: 0.089\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[640] train loss: 0.096\n",
      "generated sentence:  [UNK] it has roots in a piece of classical latin literature from 45 [UNK] making it over 2000 years [UNK] richard [UNK] a latin professor at [UNK] college in [UNK] looked up one\n",
      "[650] train loss: 0.086\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[660] train loss: 0.083\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[670] train loss: 0.083\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[680] train loss: 0.081\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[690] train loss: 0.089\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[700] train loss: 0.072\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[710] train loss: 0.070\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[720] train loss: 0.069\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[730] train loss: 0.069\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[740] train loss: 0.069\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[750] train loss: 0.069\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[760] train loss: 0.072\n",
      "generated sentence:  [UNK] and going through the cites of the word in classical [UNK] discovered the undoubtable [UNK] lorem ipsum comes from sections [UNK] and [UNK] of [UNK] finibus bonorum et [UNK] [UNK] [UNK] extremes\n",
      "[770] train loss: 0.082\n",
      "generated sentence:  [UNK] [UNK] by [UNK] written in 45 [UNK] this book is a treatise on the theory of [UNK] very popular during the [UNK] the first line of lorem [UNK] [UNK] ipsum dolor sit\n",
      "[780] train loss: 0.079\n",
      "generated sentence:  [UNK] it has roots in a piece of classical latin literature from 45 [UNK] making it over 2000 years [UNK] richard [UNK] a latin professor at [UNK] college in [UNK] looked up one\n",
      "[790] train loss: 0.066\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[800] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[810] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[820] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[830] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[840] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[850] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[860] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[870] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[880] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[890] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[900] train loss: 0.066\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[910] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[920] train loss: 0.065\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[930] train loss: 0.138\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[940] train loss: 0.081\n",
      "generated sentence:  [UNK] it uses a dictionary of over 200 latin [UNK] combined with a handful of model sentence [UNK] to generate lorem ipsum which looks [UNK] the generated lorem ipsum is therefore always free\n",
      "[950] train loss: 0.063\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[960] train loss: 0.062\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[970] train loss: 0.062\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[980] train loss: 0.062\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[990] train loss: 0.062\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "[1000] train loss: 0.062\n",
      "generated sentence:  [UNK] [UNK] ipsum dolor sit [UNK] comes from a line in section [UNK] the standard chunk of lorem ipsum used since the 1500s is reproduced below for those [UNK] sections [UNK] and [UNK]\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "text_encoder = TextEncoder(DATA_FILE_PATH)\n",
    "dataset = TextData(DATA_FILE_PATH, text_encoder, SEQUENCE_LEN)\n",
    "dataloader = DataLoader(dataset, BATCH_SIZE)\n",
    "vocab_size = text_encoder.vocab_size\n",
    "print(f\"Number of sequences in the dataset: {len(dataloader)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Model Hyperparams\n",
    "model_args = dict(n_layer=2, \n",
    "                  n_head=2, \n",
    "                  n_embd=16, \n",
    "                  block_size=SEQUENCE_LEN, # sequence length\n",
    "                  bias=True, \n",
    "                  vocab_size=vocab_size, \n",
    "                  dropout=0.0) \n",
    "\n",
    "gpt_conf = GPTConfig(**model_args)\n",
    "model = GPT(gpt_conf).to(device)\n",
    "\n",
    "print_model_size(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), LEARNING_RATE)\n",
    "\n",
    "train_loop(model, dataloader, criterion, optimizer, EPOCHS, PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a sentence and visualizing attention\n",
    "\n",
    "Now that we trained our model, we can play with it and generate sentences! (Again, keep in mind the model will only recognize words it has seen in the txt file you train on!). We can also visualize the attention.\n",
    "\n",
    "### What is Attention?\n",
    "In the context of transformer models like GPT, attention mechanisms are used to weigh the importance of different input tokens when predicting an output token. \n",
    "\n",
    "Visualizing attention weights can provide insights into the model's decision-making process. By exploring which tokens the model is focusing on when making a prediction, we can gain a better understanding of its learned patterns and potential areas of improvement.\n",
    "\n",
    "### How are we Visualizing Attention?\n",
    "In the following code, we extract the attention weights from our model and visualize them using a heatmap. The x-axis of the heatmap represents input tokens, while the color intensity represents the attention weight  darker colors indicate higher attention.\n",
    "\n",
    "<ul>\n",
    "    <li> Token Selection. We select a token of interest in a sentence and inspect how much attention it pays to other tokens when being predicted.\n",
    "    <li> Head Selection. Transformers contain multiple attention heads, each learning different patterns of attention. We select one of these heads for visualization.\n",
    "    <li> Heatmap. The heatmap represents attention weights from one token (e.g., \"gandalf\") towards all preceding tokens in the sentence.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', 'but', 'also', 'the', 'leap', 'into', 'electronic', '[UNK]', 'remaining', 'essentially', '[UNK]', 'it', 'was', 'popularised', 'in', 'the', '1960s']\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"wizard\"\n",
    "sentence, attn = generate_sentence(model, dataloader, PROMPT, 16, temperature=0.8, sample=True)\n",
    "sentence = sentence.split(\" \")\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        // There's no need to resize if the WebSocket is not connected:\n",
       "        // - If it is still connecting, then we will get an initial resize from\n",
       "        //   Python once it connects.\n",
       "        // - If it has disconnected, then resizing will clear the canvas and\n",
       "        //   never get anything back to refill it, so better to not resize and\n",
       "        //   keep something visible.\n",
       "        if (fig.ws.readyState != 1) {\n",
       "            return;\n",
       "        }\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"1000\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, attn_weights is of shape (1, model.n_head, T, T)\n",
    "# We get attention weights for our token of interest for the specified head\n",
    "token_idx = 6 #sentence.index('flying')\n",
    "head = 1\n",
    "\n",
    "attention = attn[0, head, token_idx].cpu().detach().numpy()\n",
    "attention = attention[:token_idx]\n",
    "\n",
    "# Convert the 1D vector to a 2D matrix and transpose for horizontal heatmap\n",
    "attention_matrix = attention.reshape(1, -1)\n",
    "\n",
    "# Now we'll plot the attention weights using a heatmap\n",
    "plt.subplots(figsize=(10, 4))\n",
    "sns.heatmap(attention_matrix, cmap=\"Blues\", annot=True, xticklabels=sentence[:token_idx], cbar_kws={'label': 'Attention Weight'})\n",
    "#sns.heatmap(attention_matrix, cmap=\"Blues\", cbar_kws={'label': 'Attention Weight'}, ax=ax, annot=True)\n",
    "\n",
    "\n",
    "plt.ylabel(f'Attention Weight from word x{sentence[token_idx]}')\n",
    "plt.xlabel('Tokens in Sentence')\n",
    "plt.title(f'Attention Weights of Head {head+1} for Token Index {token_idx}')\n",
    "plt.xticks(rotation=45)  # Rotate token names diagonally for better visibility\n",
    "plt.tight_layout()  # Ensures that everything fits without overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2567d625573dd00306b4578d011ae5968ef0ee87229e2f9d88073f62b5adab8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
